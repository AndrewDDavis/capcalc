#!/usr/bin/env python
#
#   Copyright 2016 Blaise Frederick
#
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.
#
#
#       $Author: frederic $
#       $Date: 2016/06/14 12:04:51 $
#       $Id: showstxcorr,v 1.11 2016/06/14 12:04:51 frederic Exp $
#
from __future__ import print_function, division
import sys
import matplotlib.pyplot as plt
import getopt
import rapidtide.tide_funcs as tide
from sklearn.cluster import KMeans, MiniBatchKMeans
from scipy import sin, arange, pi, randn
from numpy import r_, argmax, zeros, shape, reshape, eye, round, nan_to_num, transpose, asarray
import nibabel as nib

from pylab import plot, legend, show, figure


def usage():
    print("")
    print("capgeneration - calculate and cluster coactivation patterns for a set of timecourses")
    print("")
    print("usage: capgeneration -i timecoursefile --samplefreq=FREQ --sampletime=TSTEP -o outputfile [-l LABEL] [-s STARTTIME] [-D DURATION] [-F LOWERFREQ,UPPERFREQ[,LOWERSTOP,UPPERSTOP]] [-V] [-L] [-R] [-C] [--nodetrend] [-m] [-n NUMCLUSTER] [-b BATCHSIZE]")
    print("")
    print("required arguments:")
    print("    -i, --infile=TIMECOURSEFILE  - text file mulitple timeseries")
    print("    -o, --outfile=OUTNAME        - the root name of the output files")
    print("")
    print("    --samplefreq=FREQ            - sample frequency of all timecourses is FREQ ")
    print("           or")
    print("    --sampletime=TSTEP           - time step of all timecourses is TSTEP ")
    print("                                   NB: --samplefreq and --sampletime are two ways to specify")
    print("                                   the same thing.")
    print("")
    print("optional arguments:")
    print("    --nodetrend                  - do not detrend the data before correlation")
    print("    -s STARTTIME                 - time of first datapoint to use in seconds in the first file")
    print("    -D DURATION                  - amount of data to use in seconds")
    print("    -F                           - filter data and regressors from LOWERFREQ to UPPERFREQ.")
    print("                                   LOWERSTOP and UPPERSTOP can be specified, or will be calculated automatically")
    print("    -V                           - filter data and regressors to VLF band")
    print("    -L                           - filter data and regressors to LFO band")
    print("    -R                           - filter data and regressors to respiratory band")
    print("    -C                           - filter data and regressors to cardiac band")
    print('    -m                           - run MiniBatch Kmeans rather than conventional - use with very large datasets')
    print('    -n NUMCLUSTER                - set the number of clusters to NUMCLUSTER (default is 8)')
    print('    -b BATCHSIZE                 - use a batchsize of BATCHSIZE if doing MiniBatch - ignored if not.  Default is 100')
    print('    -S SEGMENTSIZE               - treat the timecourses as segments of length SEGMENTSIZE for preprocessing.')
    print('                                   Default segmentsize is the entire length')
    print('    --nonorm                     - don\'t normalize timecourses')
    print('    --pctnorm                    - scale each timecourse to it\'s percentage of the mean')
    print('    --varnorm                    - scale each timecourse to have a variance of 1.0')
    print('    --stdnorm                    - scale each timecourse to have a standard deviation of 1.0 (default)')
    print('    --ppnorm                     - scale each timecourse to have a peak to peak range of 1.0')
    print("")
    return ()


# get the command line parameters
dodetrend = True
normmethod = 'stdnorm'
minibatch = False
n_clusters = 8
max_iter = 250
n_init = 100
batch_size = 100
duration = 1000000.0
starttime = 0.0
usebutterworthfilter = False
filtorder = 3
verbose = True

# scan the command line arguments
try:
    opts, args = getopt.gnu_getopt(sys.argv[1:], "i:o:s:D:F:S:VLRCmn:b:", ["infile=", "outfile=",
                                                                                    "nodetrend",
                                                                                    "samplefreq=", "sampletime=", "help"])
except getopt.GetoptError as err:
    # print help information and exit:
    print(str(err))  # will print something like "option -x not recognized"
    usage()
    sys.exit(2)

if len(args) > 1:
    print('capgeneration takes no unflagged arguments')
    usage()
    exit()

# unset all required arguments
infilename = []
segsize = -1
sampletime = None
Fs = None
outfilename = None

theprefilter = tide.noncausalfilter()
theprefilter.setbutter(usebutterworthfilter, filtorder)

# set the default characteristics
theprefilter.settype('none')

for o, a in opts:
    if o == '--infile' or o == '-i':
        infilename.append(a)
        if verbose:
            print('will use', infilename[-1], 'as an input file')
    elif o == '--outfile' or o == '-o':
        outfilename = a
        if verbose:
            print('will use', outfilename, 'as output file')
    elif o == '-S':
        segsize = int(a)
        if verbose:
            print('Setting segment size to ', segsize)
    elif o == '--samplefreq':
        Fs = float(a)
        sampletime = 1.0 / Fs
        linkchar = '='
        if verbose:
            print('Setting sample frequency to ', Fs)
    elif o == '--sampletime':
        sampletime = float(a)
        Fs = 1.0 / sampletime
        linkchar = '='
        if verbose:
            print('Setting sample time step to ', sampletime)
    elif o == "--nonorm":
        normmethod = 'none'
    elif o == "--pctnorm":
        normmethod = 'pctnorm'
    elif o == "--stdnorm":
        normmethod = 'stdnorm'
    elif o == "--varnorm":
        normmethod = 'varnorm'
    elif o == "--ppnorm":
        normmethod = 'ppnorm'
    elif o == "--nodetrend":
        dodetrend = False
        if verbose:
            print('disabling detrending')
    elif o == "-D":
        duration = float(a)
        if verbose:
            print('duration set to', duration)
    elif o == "-s":
        starttime = float(a)
        if verbose:
            print('starttime set to', starttime)
    elif o == "-V":
        theprefilter.settype('vlf')
        if verbose:
            print('prefiltering to vlf band')
    elif o == "-L":
        theprefilter.settype('lfo')
        if verbose:
            print('prefiltering to lfo band')
    elif o == "-R":
        theprefilter.settype('resp')
        if verbose:
            print('prefiltering to respiratory band')
    elif o == "-C":
        theprefilter.settype('cardiac')
        if verbose:
            print('prefiltering to cardiac band')
    elif o == "-F":
        arbvec = a.split(',')
        if len(arbvec) != 2 and len(arbvec) != 4:
            usage()
            sys.exit()
        if len(arbvec) == 2:
            arb_lower = float(arbvec[0])
            arb_upper = float(arbvec[1])
            arb_lowerstop = 0.9 * float(arbvec[0])
            arb_upperstop = 1.1 * float(arbvec[1])
        if len(arbvec) == 4:
            arb_lower = float(arbvec[0])
            arb_upper = float(arbvec[1])
            arb_lowerstop = float(arbvec[2])
            arb_upperstop = float(arbvec[3])
        theprefilter.settype('arb')
        theprefilter.setarb(arb_lowerstop, arb_lower, arb_upper, arb_upperstop)
        if verbose:
            print('prefiltering to ', arb_lower, arb_upper, "(stops at ", arb_lowerstop, arb_upperstop, ")")
    elif o == "-m":
        minibatch = True
        print('will perform MiniBatchKMeans')
    elif o == "-b":
        batch_size = int(a)
        print('will use', batch_size, 'as batch_size (if doing MiniBatchKMeans)')
    elif o == "-n":
        n_clusters = int(a)
        print('will use', n_clusters, 'clusters')
    else:
        assert False, "unhandled option"

# check that required arguments are set
if outfilename is None:
    print('outfile must be set')
    usage()
    sys.exit()

if sampletime is None:
    print('sampletime must be set')
    usage()
    sys.exit()

if normmethod == 'none':
    print('will not normalize timecourses')
elif normmethod == 'pctnorm':
    print('will normalize timecourses to percentage of mean')
elif normmethod == 'stdnorm':
    print('will normalize timecourses to standard deviation of 1.0')
elif normmethod == 'varnorm':
    print('will normalize timecourses to variance of 1.0')
elif normmethod == 'ppnorm':
    print('will normalize timecourses to p-p deviation of 1.0')


# read in the files and get everything trimmed to the right length
startpoint = max([int(starttime * Fs), 0])
if len(infilename) == 1:
    # each column is a timecourse, each row is a timepoint
    matrixoutput = True
    inputdata = tide.readvecs(infilename[0])
    print('input data shape is ', inputdata.shape)
    numpoints = inputdata.shape[1]
    endpoint = min([startpoint + int(duration * Fs), numpoints])
    trimmeddata = inputdata[:, startpoint:endpoint]
elif len(infilename) == 2:
    inputdata1 = tide.readvec(infilename[0])
    numpoints = len(inputdata1)
    inputdata2 = tide.readvec(infilename[1])
    endpoint1 = min([startpoint + int(duration * Fs), int(len(inputdata1)), int(len(inputdata2))])
    endpoint2 = min([int(duration * Fs), int(len(inputdata1)), int(len(inputdata2))])
    trimmeddata = zeros((2, numpoints), dtype='float')
    trimmeddata[0, :] = inputdata1[startpoint:endpoint1]
    trimmeddata[1, :] = inputdata2[0:endpoint2]
else:
    print('showstxcorr requires 1 multicolumn timecourse file or two single column timecourse files as input')
    usage()
    sys.exit()
    
# band limit the regressors if that is needed
if theprefilter.gettype() != 'none':
    if verbose:
        print("filtering to ", theprefilter.gettype(), " band")

thedims=trimmeddata.shape
tclen=thedims[1]
numcomponents=thedims[0]
reformdata=reshape(trimmeddata,(numcomponents,tclen))
if segsize < 0:
    segsize = tclen
if tclen % segsize > 0:
    print('segment size is not an even divisor of the total length - exiting')
    sys.exit()
else:
    numsegs = int(tclen // segsize)
 
for component in range(0,numcomponents):
    print('preprocessing component', component)
    for segment in range(numsegs):
        segstart = segment * segsize
        if dodetrend:
            segdata = tide.detrend(reformdata[component,segstart:segstart + segsize])
        else:
            segdata = reformdata[component,segstart:segstart + segsize]
        if normmethod == 'none':
            segnorm = segdata - np.mean(segdata)
        elif normmethod == 'pctnorm':
            segnorm = tide.pcnormalize(segdata)
        elif normmethod == 'varnorm':
            segnorm = tide.varnormalize(segdata)
        elif normmethod == 'stdnorm':
            segnorm = tide.stdnormalize(segdata)
        elif normmethod == 'ppnorm':
            segnorm = tide.ppnormalize(segdata)
        reformdata[component,segstart:segstart + segsize] = theprefilter.apply(Fs, segnorm)

print('setting up kmeans')
if minibatch:
    kmeans = MiniBatchKMeans(n_clusters=n_clusters, batch_size=batch_size, max_iter=max_iter).fit(nan_to_num(transpose(reformdata)))
else:
    kmeans = KMeans(n_clusters=n_clusters, max_iter=max_iter, n_init=n_init).fit(nan_to_num(transpose(reformdata)))
theclusters = transpose(kmeans.cluster_centers_)
thestatelabels = kmeans.labels_

tide.writenpvecs(theclusters, outfilename + "_clustercenters.txt")
tide.writenpvecs(thestatelabels, outfilename + '_statelabels.txt')
